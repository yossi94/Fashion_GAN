{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ctJY7Uy9ndG",
        "colab_type": "text"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4JWKQyo-P8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Activation, LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from keras.initializers import RandomNormal\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVQ3Li9M-WMy",
        "colab_type": "text"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJlXndfX-TZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size = 112\n",
        "img_channels = 1\n",
        "latent_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQoRrndJ-jIG",
        "colab_type": "text"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjwgrpgn-maK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "4e3bf41e-7e05-445c-accf-8e422909e57a"
      },
      "source": [
        "def build_generator(img_size, img_channels, latent_dim):\n",
        "  img_shape = (img_size, img_size, img_channels)\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(7 * 7 * 128, activation=\"relu\", input_shape=(latent_dim,)))\n",
        "  model.add(Reshape((7, 7, 128)))\n",
        "  \n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  \n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  model.add(Conv2D(1, (3, 3), padding='same', activation='tanh'))\n",
        "  \n",
        "  noise = Input(shape=(latent_dim,))\n",
        "  img = model(noise)\n",
        "\n",
        "  return Model(noise, img)\n",
        "\n",
        "def build_discriminator(img_size, img_channels):\n",
        "  img_shape = (img_size, img_size, img_channels)\n",
        "\n",
        "  model = Sequential()\n",
        "  \n",
        "  init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), kernel_initializer=init, strides=(3, 3),\n",
        "                   padding='same', input_shape=img_shape))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
        "  model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same'))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  img = Input(shape=img_shape)\n",
        "  validity = model(img)\n",
        "\n",
        "  return Model(img, validity)\n",
        "\n",
        "def build_gan(g, d, img_size, img_channels, latent_dim):\n",
        "  optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "  d.compile(optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "  z = Input(shape=(latent_dim,))\n",
        "  img = g(z)\n",
        "\n",
        "  d.trainable = False\n",
        "  validity = d(img)\n",
        "\n",
        "  gan = Model(z, validity)\n",
        "  gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "  return gan\n",
        "\n",
        "g = build_generator(img_size, img_channels, latent_dim)\n",
        "d = build_discriminator(img_size, img_channels)\n",
        "\n",
        "gan = build_gan(g, d, img_size, img_channels, latent_dim)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce5TB8gA-9Nj",
        "colab_type": "text"
      },
      "source": [
        "# Training Gym\n",
        "\n",
        "### genrator vs discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaIX4uai_DUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, batch_size=64, sample_interval=200, save_image=False):\n",
        "  def noisy_labels(y, p_flip):\n",
        "    # determine the number of labels to flip\n",
        "    n_select = int(p_flip * y.shape[0])\n",
        "    # choose labels to flip\n",
        "    flip_ix = np.random.choice([i for i in range(y.shape[0])], size=n_select)\n",
        "    # invert the labels in place\n",
        "    y[flip_ix] = 1 - y[flip_ix]\n",
        "    return y\n",
        "\n",
        "  def sample_images(epoch):\n",
        "    r, c = 3, 3\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = 0.5 * g.predict(noise) + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c, figsize=(8, 8))\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "      for j in range(c):\n",
        "        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "        axs[i,j].axis('off')\n",
        "        cnt += 1\n",
        "    plt.show()\n",
        "    if save_image:\n",
        "      fig.savefig('./preview/img-{:02d}.png'.format(epoch // sample_interval),\n",
        "                  bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    if save_image:\n",
        "    !mkdir './preview'\n",
        "\n",
        "  # Load the dataset\n",
        "  X_train_orig = fashion_mnist.load_data()[0][0]\n",
        "  \n",
        "  # Resize a copy of the fashion dataset\n",
        "  X_train = []\n",
        "\n",
        "  for i in range(len(X_train_orig)):\n",
        "    im = Image.fromarray(X_train_orig[i]).convert('L')\n",
        "    im = im.resize((img_size, img_size), Image.BICUBIC)\n",
        "    X_train.append(np.array(im).astype(np.float32))\n",
        "\n",
        "  del X_train_orig\n",
        "  X_train = np.array(X_train)\n",
        "  \n",
        "  # Rescale -1 to 1\n",
        "  X_train = X_train / 127.5 - 1.\n",
        "  X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "  # Adversarial ground truths\n",
        "  valid = np.ones((batch_size, 1))\n",
        "  valid = valid - 0.3 + (np.random.random(valid.shape) * 0.5) # Smooth\n",
        "  valid = noisy_labels(valid, 0.05) # Noisy\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    # Select a random batch of images\n",
        "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "    imgs = X_train[idx]\n",
        "\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "    # Generate a batch of new images\n",
        "    gen_imgs = g.predict(noise)\n",
        "\n",
        "    # Train the discriminator\n",
        "    d_loss_real = d.train_on_batch(imgs, valid)\n",
        "    d_loss_fake = d.train_on_batch(gen_imgs, fake)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "    # Train the generator (to have the discriminator label samples as valid)\n",
        "    g_loss = gan.train_on_batch(noise, valid)\n",
        "\n",
        "    if epoch % sample_interval == 0:\n",
        "      clear_output()\n",
        "      print('Epoch: {}/{} - Loss: {}'.format(epoch, epochs, d_loss))\n",
        "      sample_images(epoch)\n",
        "      \n",
        "train(epochs=10000, save_image=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd1u9-RxAe1B",
        "colab_type": "text"
      },
      "source": [
        "# Generate New Fashion Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2y9Tb3AAZfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_image(noises, cols=3):\n",
        "  rows = -(-len(noises) // cols)\n",
        "  fig, axs = plt.subplots(rows, cols, figsize=(8, 8))\n",
        "\n",
        "  for idx, noise in enumerate(noises):\n",
        "    noise = np.random.normal(0, 1, (1, latent_dim))\n",
        "    gen_img = np.squeeze(g.predict(noise)[0])\n",
        "    gen_img = 0.5 * gen_img + 0.5\n",
        "    \n",
        "    x = idx // cols\n",
        "    y = idx % cols\n",
        "    \n",
        "    if rows > 1:\n",
        "      axs[x,y].imshow(gen_img, cmap='gray')\n",
        "      axs[x,y].axis('off')\n",
        "    else:\n",
        "      axs[y].imshow(gen_img, cmap='gray')\n",
        "      axs[y].axis('off')\n",
        "\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "noise_1 = np.random.normal(0, 1, (1, latent_dim))\n",
        "noise_2 = np.random.normal(0, 1, (1, latent_dim))\n",
        "noise_3 = np.random.normal(0, 1, (1, latent_dim))\n",
        "\n",
        "gen_image([noise_1, noise_2, noise_2])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}